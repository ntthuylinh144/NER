# NER Pipeline with Entity Management

**Complete solution for Named Entity Recognition with global entity management**

## ğŸ¯ Project Overview

This project implements a mini NER pipeline that extracts and manages named entities from technical texts using:
- **Classical NLP**: spaCy custom-trained model
- **LLM-based**: Google Gemini API with prompt engineering
- **Entity Management**: Global entity list with fuzzy matching and linking

### Core Challenge Solution
âœ… Maintains a **growing, global list** of all extracted entities  
âœ… Provides **existing entity list as context** to extraction  
âœ… **Links** newly extracted entities to existing ones (fuzzy matching)  
âœ… **Adds new** entities to the list  
âœ… Handles **context window limits** for LLMs

---

## ğŸ“ Project Structure

NER/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ner_classical.py          # Classical NER module (spaCy)
â”‚   â”œâ”€â”€ ner_llms.py               # LLM NER module (Gemini)
â”‚   â”œâ”€â”€ entity_manager.py         # Entity management system
â”‚   â””â”€â”€ ner_pipeline.py           # Main pipeline integrating all components
â”‚   â”œâ”€â”€ build_dataset.py          # Extract text from pdf file 
â”‚   â”œâ”€â”€ preprocess_texts.py       # Clean and extract command line
â”‚   â”œâ”€â”€ analysis.py               # Analyze entity distribution
â”‚   â””â”€â”€ convert_format.py         # Convert text json file to spacy json
â”‚
â”œâ”€â”€ model_ner/                    # Trained spaCy model (generated after training)
â”‚
â”œâ”€â”€ results/                                # Output results
â”‚   â”œâ”€â”€ test_file_classical_entities.json   # classical entities 
â”‚   â”œâ”€â”€ test_file_classical_results.json    # classical results 
â”‚   â”œâ”€â”€ test_file_llm_entities.json         # LLM entities
â”‚   â”œâ”€â”€ test_file_llm_results.json          # LLM results
â”‚   â””â”€â”€ entity_database.json
â”‚
â”œâ”€â”€ data_train.json               # Training data (entity annotations)
â”œâ”€â”€ data_dev.json                 # Development/test data
â”œâ”€â”€ data_test.json                # Test data
â”œâ”€â”€ test_file.json                # Sample input texts
â”œâ”€â”€ coupling_relay_3RQ1_en-US.pdf # PDF file
â”œâ”€â”€ test_file.json                # Sample input texts
â”œâ”€â”€ instructions.json             # Dataset
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # This file

---

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone repository
git clone <your-repo-url>
cd ner-pipeline

# Install dependencies
pip install -r requirements.txt

# Download spaCy model (if using pre-trained)
python -m spacy download en_core_web_sm
```

### 2. Setup API Key (for LLM)

```bash
# Get API key from: https://aistudio.google.com/apikey
export GEMINI